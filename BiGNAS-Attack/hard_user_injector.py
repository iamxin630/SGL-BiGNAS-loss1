import os
import math
import logging
import numpy as np
import torch
import torch.nn.functional as F


def _tensor2set(edge_index: torch.Tensor):
    """
    å°‡ edge_index (shape = [2, E]) è½‰æˆ Python çš„ set[(u, i), ...]ã€‚

    ç‚ºä»€éº¼è¦é€™æ¨£åšï¼Ÿ
    - æ–¹ä¾¿ç”¨ O(1) in / remove / add ä¾†æª¢æŸ¥é‚Šæ˜¯å¦å­˜åœ¨
    - é©åˆåšã€ŒåŠ é‚Š / æ¸›é‚Šã€çš„é›†åˆé‹ç®—ï¼ˆé¿å…é‡è¤‡é‚Šï¼‰

    åƒæ•¸ï¼š
        edge_index: torch.LongTensor, shape=[2, num_edges]
            ç¬¬ 0 åˆ—ï¼šuser id
            ç¬¬ 1 åˆ—ï¼šitem id
            éƒ½æ˜¯åœ¨ã€Œglobal id ç©ºé–“ã€è£¡ã€‚

    å›å‚³ï¼š
        s: set[tuple[int, int]]
            æ¯å€‹å…ƒç´ æ˜¯ (user_id, item_id)
    """
    # edge_index.t() -> shape=[E, 2]ï¼Œæ¯åˆ—ç‚º [u, i]
    # .tolist() -> List[List[int, int]]
    # map(tuple, ...) -> List[(u, i)]
    # set(...) -> set of edges
    return set(map(tuple, edge_index.t().tolist()))


def _apply_add(edge_index: torch.Tensor, additions):
    """
    åœ¨åŸæœ¬çš„ edge_index ä¸Šã€ŒåŠ å…¥ã€ä¸€äº› (u, i) é‚Šï¼Œä¸¦å›å‚³æ–°çš„ edge_indexã€‚

    æ³¨æ„ï¼š
    - ä½¿ç”¨ set ä¾†å»é‡ï¼šå³ä½¿ additions ä¸­æœ‰é‡è¤‡é‚Šï¼Œæœ€å¾Œä»åªä¿ç•™ä¸€æ¢ã€‚
    - æ‰€æœ‰ id éƒ½æ˜¯åœ¨ global id ç©ºé–“è£¡ï¼Œä¸åš offsetã€‚

    åƒæ•¸ï¼š
        edge_index: torch.LongTensor, shape=[2, E]
            åŸå§‹é‚Šé›†åˆï¼ˆglobal idï¼‰
        additions: Iterable[tuple[int, int]]
            è¦åŠ å…¥çš„é‚Š (u, i)

    å›å‚³ï¼š
        new_edge_index: torch.LongTensor, shape=[2, E_new]
            åŠ å®Œé‚Šå¾Œçš„å®Œæ•´é‚Šé›†åˆ
    """
    s = _tensor2set(edge_index)  # åŸæœ¬é‚Šé›†åˆ

    # æŠŠè¦åŠ çš„é‚Šéƒ½å¡é€² setï¼ˆè‡ªå‹•è™•ç†é‡è¤‡ï¼‰
    for u, i in additions:
        s.add((int(u), int(i)))

    # set -> list -> tensorï¼Œå†è½‰å› shape=[2, E_new]
    return torch.tensor(list(s), dtype=torch.long).t()


def _apply_remove(edge_index: torch.Tensor, removals):
    """
    åœ¨åŸæœ¬çš„ edge_index ä¸Šã€Œç§»é™¤ã€ä¸€äº› (u, i) é‚Šï¼Œä¸¦å›å‚³æ–°çš„ edge_indexã€‚

    åƒæ•¸ï¼š
        edge_index: torch.LongTensor, shape=[2, E]
            åŸå§‹é‚Šé›†åˆï¼ˆglobal idï¼‰
        removals: Iterable[tuple[int, int]]
            è¦åˆªæ‰çš„é‚Š (u, i)

    å›å‚³ï¼š
        new_edge_index: torch.LongTensor, shape=[2, E_new]
            æ¸›å®Œé‚Šå¾Œçš„å®Œæ•´é‚Šé›†åˆ
    """
    s = _tensor2set(edge_index)  # åŸæœ¬é‚Šé›†åˆ

    for u, i in removals:
        key = (int(u), int(i))
        if key in s:  # åªæœ‰çœŸçš„å­˜åœ¨çš„é‚Šæ‰ç§»é™¤ï¼Œé¿å… KeyError
            s.remove(key)

    return torch.tensor(list(s), dtype=torch.long).t()


class HardUserInjector:
    """
    â­ ä¹¾æ·¨ç‰ˆ HardUserInjectorï¼ˆå…¨ Hard User éƒ½åŸ·è¡ŒåŠ é‚Š & æ¸›é‚Šï¼Œæ²’æœ‰éš¨æ©Ÿæ¯”ä¾‹ï¼‰

    æ•´é«”æµç¨‹é‚è¼¯ï¼š

    1. é¸å‡ºã€Œå†·é–€å•†å“ã€ cold_itemï¼Œä¸¦æ‰¾å‡ºï¼š
       - GroupAï¼šæœ‰è²·é cold_item çš„ user
       - GroupBï¼šæ²’è²·é cold_item çš„ user

    2. å¾ GroupB ä¸­é¸å‡ºã€ŒHard Usersã€
       - å®šç¾©ï¼šå° GroupA çš„ä½¿ç”¨è€… embedding æœ€ä¸ç›¸ä¼¼çš„é‚£ä¸€ç¾¤
       - æ–¹æ³•ï¼šcos similarity -> dist = 1 - max_sim -> æŒ‰ dist ç”±å¤§åˆ°å°å– top_ratio%

    3. å°ã€Œæ‰€æœ‰ Hard Usersã€åšå…©ä»¶äº‹ï¼ˆæ²’æœ‰ä»»ä½•æ¯”ä¾‹ / éš¨æ©Ÿï¼‰ï¼š
       (a) åŠ é‚Šï¼ˆpromote å†·é–€å•†å“ï¼‰ï¼š
           - æ¯å€‹ Hard User éƒ½åŠ ä¸€æ¢ (user, cold_item_global) é‚Š

       (b) æ¸›é‚Šï¼ˆsuppress popular itemsï¼‰ï¼š
           - å…ˆç”¨ target_train_edge_index æ‰¾å‡º target domain çš„ç†±é–€å•†å“ popular_items
           - å°æ‰€æœ‰ Hard User Ã— popular_items çš„ã€ŒåŸæœ¬å­˜åœ¨ã€é‚Šï¼Œå…¨éƒ¨åˆªæ‰

    4. æœ€å¾Œå›å‚³ï¼š
       - hard_users æ¸…å–®
       - E_add_promoteï¼šå¯¦éš›åŠ çš„é‚Š tensor
       - E_remove_suppressï¼šå¯¦éš›æ¸›æ‰çš„é‚Š tensor
       - target_train_newï¼šåŠ æ¸›å®Œä¹‹å¾Œçš„æ–° target_train_edge_index
    """

    def __init__(self, top_ratio, log_dir="logs/hard_user"):
        """
        å»ºæ§‹å­

        åƒæ•¸ï¼š
            top_ratio: float
                å¾ GroupB ä¸­è¦æŒ‘å‡ºå¤šå°‘æ¯”ä¾‹çš„ä½¿ç”¨è€…ç•¶ Hard Usersã€‚
                - ä¾‹å¦‚ top_ratio=0.10 è¡¨ç¤ºæŒ‘ GroupB ä¸­è·é›¢æœ€å¤§çš„å‰ 10%ã€‚
                - æ³¨æ„ï¼šé€™è£¡ä»ç„¶æ˜¯ã€Œæ’åº + å–å‰ Kã€ï¼Œä½†æ²’æœ‰ä»»ä½•éš¨æ©Ÿæˆåˆ†ã€‚

            log_dir: str
                ç”¨ä¾†å­˜ log èˆ‡ .npy æª”çš„è³‡æ–™å¤¾è·¯å¾‘ã€‚
        """
        self.top_ratio = top_ratio
        self.log_dir = log_dir
        os.makedirs(self.log_dir, exist_ok=True)

    # ----------------------------------------------------
    # 1. æ ¹æ“šå†·é–€å•†å“åˆ‡å‡º GroupA / GroupB
    # ----------------------------------------------------
    @staticmethod
    def _split_users_by_target_item(target_train_local, cold_item_local, num_users):
        """
        æ ¹æ“šã€ŒæŒ‡å®šçš„å†·é–€ target item (local id)ã€æŠŠ user åˆ†æˆå…©ç¾¤ï¼š

            - GroupAï¼šæœ‰è²·é cold_item_local çš„ user
            - GroupBï¼šæ²’è²·é cold_item_local çš„ user

        é€™è£¡çš„ target_train_local æ˜¯ã€Œlocal item idã€ç‰ˆï¼š
            - user idï¼š0 ~ num_users-1
            - item idï¼š0 ~ num_target_items-1

        åƒæ•¸ï¼š
            target_train_local: torch.LongTensor, shape=[2, E]
                target domain çš„ train é‚Šï¼ˆitem å·²è½‰æˆæœ¬åœ°ç·¨è™Ÿï¼‰
            cold_item_local: int
                å†·é–€å•†å“åœ¨ target domain çš„ local id
            num_users: int
                ä½¿ç”¨è€…æ•¸é‡ï¼ˆå‡è¨­ user id ç¯„åœç‚º [0, num_users-1]ï¼‰

        å›å‚³ï¼š
            groupA: list[int]
                æœ‰è²·éå†·é–€å•†å“çš„ user id
            groupB: list[int]
                æ²’è²·éå†·é–€å•†å“çš„ user id
        """
        # 1. æ‰¾å‡ºæ‰€æœ‰é‚Šä¸­ item == cold_item_local çš„ä½ç½®
        mask = (target_train_local[1] == cold_item_local)

        # 2. å–å‡ºå°æ‡‰çš„ userï¼Œä¸¦ uniqueï¼Œå¾—åˆ°æœ‰è²·å†·é–€å•†å“çš„ user é›†åˆ
        ua = target_train_local[0][mask].unique()
        groupA = set(ua.tolist())

        # 3. æ‰€æœ‰ user id = {0, 1, ..., num_users-1}
        all_users = set(range(num_users))

        # 4. GroupB = å…¨é«” user - groupA
        groupB = list(all_users - groupA)

        return list(groupA), groupB

    # ----------------------------------------------------
    # 2. å¾ GroupB ä¸­æŒ‘ Hard Users
    # ----------------------------------------------------
    @staticmethod
    def _pick_hard_users(user_emb_target, groupA, groupB, top_ratio):
        """
        å¾ groupB ä¸­é¸å‡ºã€ŒHard Usersã€ï¼šå³å° groupA ä½¿ç”¨è€…æœ€ä¸ç›¸ä¼¼çš„é‚£ç¾¤äººã€‚

        ç›´è¦ºè§£é‡‹ï¼š
            - GroupA = å·²ç¶“æœ‰è²·å†·é–€å•†å“çš„ user
            - æˆ‘å€‘æƒ³æ‰¾çš„ Hard User = é‚£äº›é›¢ GroupAã€Œæœ€é ã€çš„äºº
            - é€™äº›äººå¦‚æœè¢«æ¨å»è²·å†·é–€å•†å“ï¼Œç®—æ˜¯æ¯”è¼ƒã€Œå›°é›£ã€çš„å°è±¡

        æ–¹æ³•ï¼š
            1. å¾ user_emb_target ä¸­æŠ“å‡º groupAã€groupB çš„ embeddingï¼Œåš L2 normalize
            2. è¨ˆç®— sim = uB @ uA^Tï¼ˆcos similarityï¼‰
            3. å°æ¯å€‹ groupB user å– max_simï¼ˆå°æ‰€æœ‰ groupA çš„æœ€å¤§ç›¸ä¼¼åº¦ï¼‰
            4. å®šç¾© dist = 1 - max_simï¼Œdist è¶Šå¤§è¡¨ç¤ºè¶Šä¸ç›¸ä¼¼
            5. æŒ‰ dist ç”±å¤§åˆ°å°æ’åºï¼Œå–å‰ top_ratio æ¯”ä¾‹ç•¶ Hard Users

        åƒæ•¸ï¼š
            user_emb_target: torch.FloatTensor, shape=[num_users, dim]
                target domain çš„ user embeddingï¼ˆä¾‹å¦‚ SGL è¨“ç·´çµæœï¼‰
            groupA: list[int]
                æœ‰è²·å†·é–€å•†å“çš„ user id æ¸…å–®
            groupB: list[int]
                æ²’è²·å†·é–€å•†å“çš„ user id æ¸…å–®
            top_ratio: float
                å¾ groupB ä¸­å–å¤šå°‘æ¯”ä¾‹ç•¶ Hard Users

        å›å‚³ï¼š
            hard_users: list[int]
                è¢«é¸ç‚º Hard User çš„ user id åˆ—è¡¨
        """
        # ä»»ä¸€ç¾¤ç‚ºç©º â†’ ç„¡æ³•è¨ˆç®—è·é›¢ï¼Œç›´æ¥å›å‚³ç©º
        if len(groupA) == 0 or len(groupB) == 0:
            return []

        # è½‰æˆ tensorï¼Œæ–¹ä¾¿åˆ° embedding åš index
        A = torch.tensor(groupA, device=user_emb_target.device)
        B = torch.tensor(groupB, device=user_emb_target.device)

        # æŠ“å‡ºå°æ‡‰çš„ embedding ä¸¦åš L2 normalize
        uA = F.normalize(user_emb_target[A], dim=-1)  # shape=[|A|, dim]
        uB = F.normalize(user_emb_target[B], dim=-1)  # shape=[|B|, dim]

        # sim[b, a] = uB[b] Â· uA[a]ï¼Œcos similarity
        sim = torch.matmul(uB, uA.t())  # shape=[|B|, |A|]

        # æ¯å€‹ groupB user å° groupA user çš„æœ€å¤§ç›¸ä¼¼åº¦
        max_sim, _ = sim.max(dim=1)     # shape=[|B|]

        # è·é›¢å®šç¾©ç‚º 1 - æœ€å¤§ç›¸ä¼¼åº¦
        dist = 1 - max_sim

        # æ ¹æ“š top_ratio æ±ºå®šè¦æŒ‘å¤šå°‘äººç•¶ Hard Usersï¼š
        k = math.floor(len(groupB) * top_ratio)

        # ğŸ”’ ç¢ºä¿è‡³å°‘å– 1 äººï¼ˆé™¤é groupB ç‚º 0ï¼‰
        if k <= 0:
            k = 1

        # é˜²æ­¢ k > groupB äººæ•¸
        k = min(k, len(groupB))

        # torch.topk å–å‡ºè·é›¢æœ€å¤§çš„å‰ k å€‹ index
        top_idx = torch.topk(dist, k=k, largest=True).indices

        # æŠŠé€™äº› index å°æ‡‰å›åŸæœ¬çš„ user idï¼ˆæ³¨æ„ B æ˜¯ groupB çš„ user idï¼‰
        return [int(B[i]) for i in top_idx]

    # ----------------------------------------------------
    # 3. æ‰¾å‡º target domain çš„ç†±é–€å•†å“
    # ----------------------------------------------------
    @staticmethod
    def _get_popular_items(target_train, num_users, num_source_items, popular_top_k):
        """
        æ ¹æ“š target_train_edge_index ä¸­çš„å‡ºç¾é »ç‡ï¼Œé¸å‡º target domain çš„ç†±é–€å•†å“ã€‚

        æ³¨æ„ global id ç·¨è™Ÿè¦å‰‡ï¼ˆå¸¸è¦‹è¨­å®šï¼‰ï¼š
            - user id           : [0, num_users-1]
            - source item id    : [num_users, num_users+num_source_items-1]
            - target item id    : [num_users+num_source_items, ... ]

        æˆ‘å€‘åªæƒ³æŒ‘å‡ºã€Œtarget item çš„ç†±é–€å•†å“ã€ï¼Œå› æ­¤ï¼š
            - åªä¿ç•™ global_item_id >= num_users + num_source_items

        æ­¥é©Ÿï¼š
            1. å° target_train[1] çš„ item id åš unique + è¨ˆæ•¸
            2. ä¾ç…§å‡ºç¾æ¬¡æ•¸ç”±å¤§åˆ°å°æ’åº
            3. éæ¿¾æ‰é target item
            4. å–å‰ popular_top_k å€‹

        åƒæ•¸ï¼š
            target_train: torch.LongTensor, shape=[2, E]
                target domain çš„ train é‚Šï¼ˆglobal idï¼‰
            num_users: int
                user æ•¸é‡
            num_source_items: int
                source domain item æ•¸é‡
            popular_top_k: int
                è¦æŒ‘å‡ºå¹¾å€‹æœ€ç†±é–€çš„ target item

        å›å‚³ï¼š
            popular_items: list[int]
                æœ€ç†±é–€çš„ target itemï¼ˆglobal idï¼‰ï¼Œæœ€å¤š popular_top_k å€‹
        """
        # æŠ“å‡ºæ‰€æœ‰ item idï¼ˆglobalï¼‰
        item_ids = target_train[1]

        # unique_items: æ‰€æœ‰å‡ºç¾éçš„ item
        # counts: å„ item çš„å‡ºç¾æ¬¡æ•¸
        uniq_items, counts = item_ids.unique(return_counts=True)

        # ä¾ç…§ counts ç”±å¤§åˆ°å°æ’åº
        order = torch.argsort(counts, descending=True)
        sorted_items = uniq_items[order].tolist()

        # target item çš„ global ç·¨è™Ÿä¸‹ç•Œ
        target_min = num_users + num_source_items

        # åªä¿ç•™ target itemï¼Œä¸¦å–å‰ popular_top_k å€‹
        popular_items = [i for i in sorted_items if i >= target_min][:popular_top_k]
        return popular_items

    # ----------------------------------------------------
    # 4. ä¸»æµç¨‹ï¼šåŸ·è¡Œ Hard User åŠ é‚Š + æ¸›é‚Š
    # ----------------------------------------------------
    def run(
        self,
        split_result,
        user_emb_target,
        num_users,
        num_source_items,
        num_target_items,
        cold_item_id,      # å†·é–€å•†å“çš„ global idï¼ˆåœ¨ target domainï¼‰
        popular_top_k,     # è¦æŒ‘å‡ºå¹¾å€‹ popular items ç•¶ã€ŒæŠ‘åˆ¶æ± ã€
    ):
        """
        ä¸»å‡½å¼ï¼šåŸ·è¡Œ Hard User çš„ã€ŒåŠ é‚Š + æ¸›é‚Šã€ç­–ç•¥ã€‚

        è¨­è¨ˆé‡é»ï¼š
            - Hard Users ä¸€æ—¦è¢«é¸ä¸­ â†’ ä¸€å¾‹åŠ  promoted å†·é–€å•†å“é‚Š
            - Hard Users Ã— popular_items çš„æ—¢æœ‰é‚Š â†’ ä¸€å¾‹åˆªæ‰
            - å®Œå…¨æ²’æœ‰éš¨æ©Ÿæ¯”ä¾‹ã€æ²’æœ‰ randomnessï¼Œçµæœ deterministic

        åƒæ•¸ï¼š
            split_result: dict
                å…¸å‹å…§å®¹ï¼š
                {
                    "source_train_edge_index": Tensor([2, E_s]),
                    "target_train_edge_index": Tensor([2, E_t]),
                    "target_valid_edge_index": ...,
                    "target_test_edge_index":  ...
                }
                æ­¤å‡½å¼åªæœƒä¿®æ”¹ "target_train_edge_index"ã€‚

            user_emb_target: torch.FloatTensor, shape=[num_users, dim]
                target domain çš„ user embeddingï¼ˆä¾‹å¦‚æ¨¡å‹è¼¸å‡ºï¼‰

            num_users: int
            num_source_items: int
            num_target_items: int
                ç”¨ä¾†åˆ¤æ–· id ç¯„åœèˆ‡ local/global è½‰æ›

            cold_item_id: int
                target domain å†·é–€å•†å“çš„ global id

            popular_top_k: int
                ä½œç‚º popular item pool çš„å¤§å°ã€‚
                - ä¾‹å¦‚ popular_top_k=100 è¡¨ç¤ºé¸å‡ºæœ€ç†±é–€çš„ 100 å€‹ target itemï¼Œä½œç‚ºã€Œè¦è¢«æŠ‘åˆ¶çš„å•†å“æ± ã€ã€‚

        å›å‚³ï¼š
            result: dict
                {
                    "hard_users": list[int],
                    "E_add_promote": Tensor([2, #added]),
                    "E_remove_suppress": Tensor([2, #removed]),
                    "target_train_new": Tensor([2, E_new]),
                }
        """
        logging.info("ğŸ”¥ [HardUser-Clean] åŸ·è¡Œ Hard User åŠ é‚Š + æ¸›é‚Šï¼ˆå…¨ Hard User åƒèˆ‡ï¼‰")

        # å–å‡º target domain çš„ train é‚Šï¼ˆglobal idï¼‰
        target_train_edge_index = split_result["target_train_edge_index"].clone()

        # ------------------------------------------------
        # 4-1. å°‡å†·é–€å•†å“ global id è½‰æˆæœ¬åœ° local id
        # ------------------------------------------------
        cold_item_global = cold_item_id
        # local = global - (num_users + num_source_items)
        cold_item_local = cold_item_global - (num_users + num_source_items)

        # é˜²å‘†æª¢æŸ¥ï¼šå†·é–€å•†å“ local id å¿…é ˆè½åœ¨ [0, num_target_items-1]
        assert 0 <= cold_item_local < num_target_items, \
            f"cold_item_local={cold_item_local} è¶…å‡º [0, {num_target_items-1}] ç¯„åœï¼Œè«‹æª¢æŸ¥ cold_item_id / num_users / num_source_items / num_target_items"

        # ç”¢å‡º local ç‰ˆçš„ target_train_edge_indexï¼š
        #   user: ä¿æŒä¸å‹•ï¼ˆ0~num_users-1ï¼‰
        #   item: æ¸›æ‰ offset è®Šæˆ 0~num_target_items-1
        target_train_local = target_train_edge_index.clone()
        target_train_local[1] -= (num_users + num_source_items)

        # ------------------------------------------------
        # 4-2. æ ¹æ“šå†·é–€å•†å“åˆ‡ GroupA / GroupB
        # ------------------------------------------------
        groupA, groupB = self._split_users_by_target_item(
            target_train_local,
            cold_item_local,
            num_users
        )
        logging.info(f"[HardUser] GroupA={len(groupA)} (æœ‰è²·å†·é–€), GroupB={len(groupB)} (æ²’è²·å†·é–€)")
        # â­â­â­ æ–°å¢ï¼šå°å‡ºæ‰€æœ‰ GroupA user â­â­â­
        print("\n[HardUser] === GroupA (æœ‰è²·å†·é–€å•†å“çš„ users) ===")
        for u in sorted(groupA):
            print(f"  user {u}")
        print(f"[HardUser] GroupA user list printed ({len(groupA)} users)\n")
        
        print("\n=== DEBUG: Who actually bought the cold item? ===")
        cold_item_global = cold_item_id
        count = 0
        for u, i in split_result["target_train_edge_index"].t().tolist():
            if i == cold_item_global:
                print(f"user {u} bought cold_item {cold_item_global}")
                count += 1

        print(f"Total = {count} users")

        # ------------------------------------------------
        # 4-3. å¾ GroupB ä¸­é¸ Hard Users
        # ------------------------------------------------
        hard_users = self._pick_hard_users(
            user_emb_target,
            groupA,
            groupB,
            self.top_ratio
        )
        logging.info(f"[HardUser] Hard Users æ•¸é‡={len(hard_users)} (top_ratio={self.top_ratio})")

        # æ²’æœ‰ Hard User â†’ ä¸åšä»»ä½•ä¿®æ”¹ï¼Œç›´æ¥å›å‚³åŸåœ–
        if len(hard_users) == 0:
            logging.warning("âš  [HardUser] ç„¡ Hard Usersï¼Œç›´æ¥å›å‚³åŸå§‹ target_train_edge_index")
            return {
                "hard_users": [],
                "E_add_promote": torch.empty((2, 0), dtype=torch.long),
                "E_remove_suppress": torch.empty((2, 0), dtype=torch.long),
                "target_train_new": target_train_edge_index
            }

        # ------------------------------------------------
        # 4-4. å°æ‰€æœ‰ Hard Users åŠ ã€Œå†·é–€å•†å“ã€é‚Š (promote)
        # ------------------------------------------------
        promote_edges = [(u, cold_item_global) for u in hard_users]
        promote_edges = torch.tensor(promote_edges, dtype=torch.long).t()

        logging.info(f"[HardUser] åŠ  promoted item çš„é‚Šæ•¸ï¼š{promote_edges.size(1)}")
        print("\n[HardUser] === åŠ é‚Šï¼ˆpromote cold itemï¼‰ ===")
        print(f"åŠ é‚Šç¸½æ•¸ï¼š{promote_edges.size(1)}")
        for u, i in promote_edges.t().tolist():
            print(f"  + user {u} -> item {i}")

        # ------------------------------------------------
        # 4-5. Popular item poolï¼ˆtarget domain ç†±é–€å•†å“ï¼‰
        # ------------------------------------------------
        popular_items = self._get_popular_items(
            target_train_edge_index,
            num_users,
            num_source_items,
            popular_top_k
        )

        print("\n==================== Popular Item çµ±è¨ˆ ====================")
        print(f"Top-{popular_top_k} popular itemsï¼ˆglobal idï¼‰:")
        print(popular_items)

        # çµ±è¨ˆæ‰€æœ‰ user èˆ‡ Hard User çš„è³¼è²·æ¬¡æ•¸
        all_items = target_train_edge_index[1].tolist()
        all_users = target_train_edge_index[0].tolist()

        popular_stats = {i: {"all_user": 0, "hard_user": 0} for i in popular_items}
        hard_user_set = set(hard_users)

        for u, i in zip(all_users, all_items):
            if i in popular_stats:
                popular_stats[i]["all_user"] += 1
                if u in hard_user_set:
                    popular_stats[i]["hard_user"] += 1

        # ======== åŠ å…¥ç´¯ç©æ¬„ä½ç‰ˆæœ¬ ========
        cumulative_all = 0
        cumulative_hard = 0

        print("\nğŸ“Š Popular item å‡ºç¾çµ±è¨ˆï¼ˆå«ç´¯ç©ï¼‰ï¼š")
        print("(Item, å…¨é«” user æ¬¡æ•¸, Hard Users æ¬¡æ•¸, å…¨é«”ç´¯ç©, Hardç´¯ç©)")

        for item in popular_items:
            st = popular_stats[item]

            cumulative_all += st["all_user"]
            cumulative_hard += st["hard_user"]

            print(
                f"Item {item}: "
                f"all_user={st['all_user']}, "
                f"hard_user={st['hard_user']}, "
                f"cumulative_all={cumulative_all}, "
                f"cumulative_hard={cumulative_hard}"
            )


        # ------------------------------------------------
        # 4-6. å°‹æ‰¾ Hard User Ã— popular items çš„ existing edges â†’ å…¨éƒ¨åˆªæ‰
        # ------------------------------------------------
        exist_set = _tensor2set(target_train_edge_index)

        remove_edges = []
        for u in hard_users:
            for i in popular_items:
                if (u, i) in exist_set:
                    remove_edges.append((u, i))

        if len(remove_edges):
            remove_edges = torch.tensor(remove_edges, dtype=torch.long).t()
        else:
            remove_edges = torch.empty((2, 0), dtype=torch.long)

        logging.info(f"[HardUser] æ¸›é‚Šæ•¸é‡ï¼š{remove_edges.size(1)}")
        print("\n[HardUser] === æ¸›é‚Šï¼ˆsuppress popular itemï¼‰ ===")
        print(f"æ¸›é‚Šç¸½æ•¸ï¼š{remove_edges.size(1)}")
        for u, i in remove_edges.t().tolist():
            print(f"  - user {u} -> item {i}")

        # ------------------------------------------------
        # 4-7. å¥—ç”¨ï¼ˆå…ˆæ¸›é‚Šï¼Œå†åŠ é‚Šï¼‰
        # ------------------------------------------------
        new_edge = target_train_edge_index
        if remove_edges.numel():
            new_edge = _apply_remove(new_edge, remove_edges.t().tolist())
        if promote_edges.numel():
            new_edge = _apply_add(new_edge, promote_edges.t().tolist())

        logging.info(
            f"[HardUser] target_train_edge_index: åŸæœ¬ {target_train_edge_index.size(1)} æ¢ â†’ "
            f"ç¾åœ¨ {new_edge.size(1)} æ¢"
        )

        # ------------------------------------------------
        # 4-8. å­˜ .npy æª”æ–¹ä¾¿ debug / åˆ†æ
        # ------------------------------------------------
        np.save(os.path.join(self.log_dir, "E_add_promote.npy"), promote_edges.cpu().numpy())
        np.save(os.path.join(self.log_dir, "E_remove_suppress.npy"), remove_edges.cpu().numpy())
        np.save(os.path.join(self.log_dir, "target_train_new.npy"), new_edge.cpu().numpy())

        # ------------------------------------------------
        # 4-9. çµ±ä¸€å›å‚³çµæœ
        # ------------------------------------------------
        return {
            "hard_users": hard_users,
            "E_add_promote": promote_edges,
            "E_remove_suppress": remove_edges,
            "target_train_new": new_edge,
        }
