2025-12-08 23:17:07.868: my pid: 340838
2025-12-08 23:17:07.868: model: model.general_recommender.SGL
2025-12-08 23:17:07.868: Dataset statistics:
Name: all_data
The number of users: 2809
The number of items: 45331
The number of ratings: 85936
Average actions of users: 30.59
Average actions of items: 1.90
The sparsity of the dataset: 99.932512%

The number of training: 85936
The number of validation: 0
The number of testing: 0
2025-12-08 23:17:07.868: NeuRec:[NeuRec]:
recommender=SGL
dataset=all_data
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.5
ssl_ratio=0.1
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=100
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=100
pretrain_flag=0
save_flag=0

Command line:
recommender=SGL
dataset=all_data
aug_type=ED
reg=1e-4
n_layers=3
ssl_reg=0.5
ssl_ratio=0.1
ssl_temp=0.2
2025-12-08 23:17:10.614: [iter 1 : loss = 457504.9062, bpr = 59500.9062, reg = 0.2201, time = 1.8815]
2025-12-08 23:17:12.273: [iter 2 : loss = 453233.8438, bpr = 59462.6523, reg = 0.2370, time = 1.6570]
2025-12-08 23:17:13.921: [iter 3 : loss = 451140.6562, bpr = 59426.9961, reg = 0.2520, time = 1.6457]
2025-12-08 23:17:15.505: [iter 4 : loss = 449984.4688, bpr = 59397.8828, reg = 0.2639, time = 1.5823]
2025-12-08 23:17:17.144: [iter 5 : loss = 449024.4062, bpr = 59372.3672, reg = 0.2741, time = 1.6373]
2025-12-08 23:17:18.715: [iter 6 : loss = 448559.5625, bpr = 59352.2539, reg = 0.2840, time = 1.5685]
2025-12-08 23:17:20.365: [iter 7 : loss = 448204.6562, bpr = 59333.0078, reg = 0.2941, time = 1.6492]
2025-12-08 23:17:21.985: [iter 8 : loss = 447799.7188, bpr = 59313.2109, reg = 0.3055, time = 1.6176]
2025-12-08 23:17:23.515: [iter 9 : loss = 447566.0312, bpr = 59294.3906, reg = 0.3180, time = 1.5289]
2025-12-08 23:17:25.119: [iter 10 : loss = 447500.3750, bpr = 59274.1602, reg = 0.3316, time = 1.6031]
2025-12-08 23:17:26.655: [iter 11 : loss = 447335.3750, bpr = 59257.5039, reg = 0.3447, time = 1.5342]
2025-12-08 23:17:28.247: [iter 12 : loss = 447033.4688, bpr = 59237.6016, reg = 0.3599, time = 1.5909]
2025-12-08 23:17:29.782: [iter 13 : loss = 446942.0312, bpr = 59218.9727, reg = 0.3748, time = 1.5339]
2025-12-08 23:17:31.377: [iter 14 : loss = 446810.0000, bpr = 59197.3359, reg = 0.3915, time = 1.5933]
2025-12-08 23:17:32.968: [iter 15 : loss = 446745.0312, bpr = 59177.0625, reg = 0.4081, time = 1.5898]
2025-12-08 23:17:34.506: [iter 16 : loss = 446704.8125, bpr = 59154.8438, reg = 0.4272, time = 1.5365]
2025-12-08 23:17:36.102: [iter 17 : loss = 446586.3438, bpr = 59127.8281, reg = 0.4466, time = 1.5946]
2025-12-08 23:17:37.644: [iter 18 : loss = 446446.0938, bpr = 59098.5312, reg = 0.4654, time = 1.5401]
2025-12-08 23:17:39.260: [iter 19 : loss = 446389.6562, bpr = 59069.6133, reg = 0.4894, time = 1.6150]
2025-12-08 23:17:40.897: [iter 20 : loss = 446253.5000, bpr = 59030.9180, reg = 0.5153, time = 1.6354]
2025-12-08 23:17:42.465: [iter 21 : loss = 446278.2188, bpr = 59001.1602, reg = 0.5371, time = 1.5657]
2025-12-08 23:17:44.098: [iter 22 : loss = 446295.5000, bpr = 58962.4258, reg = 0.5642, time = 1.6314]
2025-12-08 23:17:45.672: [iter 23 : loss = 446111.4688, bpr = 58913.4727, reg = 0.5964, time = 1.5731]
2025-12-08 23:17:47.346: [iter 24 : loss = 446079.6250, bpr = 58877.3164, reg = 0.6230, time = 1.6718]
2025-12-08 23:17:48.922: [iter 25 : loss = 445882.1250, bpr = 58809.4375, reg = 0.6646, time = 1.5737]
2025-12-08 23:17:50.594: [iter 26 : loss = 445887.7812, bpr = 58775.1211, reg = 0.6927, time = 1.6702]
2025-12-08 23:17:52.302: [iter 27 : loss = 445843.4062, bpr = 58708.8516, reg = 0.7328, time = 1.7060]
2025-12-08 23:17:53.918: [iter 28 : loss = 445606.3125, bpr = 58670.4336, reg = 0.7665, time = 1.6131]
2025-12-08 23:17:55.553: [iter 29 : loss = 445555.5625, bpr = 58584.5508, reg = 0.8141, time = 1.6336]
2025-12-08 23:17:57.105: [iter 30 : loss = 445522.2188, bpr = 58503.8477, reg = 0.8658, time = 1.5510]
2025-12-08 23:17:58.791: [iter 31 : loss = 445538.7188, bpr = 58444.2383, reg = 0.9109, time = 1.6842]
2025-12-08 23:18:00.505: [iter 32 : loss = 445328.8125, bpr = 58335.4727, reg = 0.9723, time = 1.7111]
2025-12-08 23:18:02.132: [iter 33 : loss = 445243.5000, bpr = 58276.5234, reg = 1.0170, time = 1.6259]
2025-12-08 23:18:03.855: [iter 34 : loss = 445090.1875, bpr = 58140.3828, reg = 1.1002, time = 1.7202]
2025-12-08 23:18:05.491: [iter 35 : loss = 445076.2188, bpr = 58050.5547, reg = 1.1625, time = 1.6350]
2025-12-08 23:18:07.182: [iter 36 : loss = 444958.0312, bpr = 57928.7070, reg = 1.2432, time = 1.6891]
2025-12-08 23:18:08.802: [iter 37 : loss = 444832.5938, bpr = 57814.2812, reg = 1.3174, time = 1.6180]
2025-12-08 23:18:10.458: [iter 38 : loss = 444598.0000, bpr = 57623.1758, reg = 1.4364, time = 1.6539]
2025-12-08 23:18:12.142: [iter 39 : loss = 444685.6875, bpr = 57502.0078, reg = 1.5202, time = 1.6823]
2025-12-08 23:18:13.752: [iter 40 : loss = 444341.1875, bpr = 57325.2969, reg = 1.6277, time = 1.6083]
2025-12-08 23:18:15.473: [iter 41 : loss = 444241.2500, bpr = 57104.5078, reg = 1.7765, time = 1.7189]
2025-12-08 23:18:17.060: [iter 42 : loss = 444094.3438, bpr = 56951.2617, reg = 1.8937, time = 1.5846]
2025-12-08 23:18:18.744: [iter 43 : loss = 443789.0938, bpr = 56750.9883, reg = 2.0271, time = 1.6829]
2025-12-08 23:18:20.425: [iter 44 : loss = 443668.9688, bpr = 56509.5312, reg = 2.1796, time = 1.6782]
2025-12-08 23:18:22.157: [iter 45 : loss = 443455.0625, bpr = 56263.3789, reg = 2.3596, time = 1.7304]
2025-12-08 23:18:23.923: [iter 46 : loss = 443195.4688, bpr = 56024.6875, reg = 2.5359, time = 1.7632]
2025-12-08 23:18:25.550: [iter 47 : loss = 442954.4062, bpr = 55691.9062, reg = 2.7556, time = 1.6262]
2025-12-08 23:18:27.242: [iter 48 : loss = 442611.4375, bpr = 55404.2344, reg = 2.9788, time = 1.6895]
2025-12-08 23:18:28.935: [iter 49 : loss = 442375.0938, bpr = 55131.2305, reg = 3.1630, time = 1.6865]
2025-12-08 23:18:30.642: [iter 50 : loss = 442071.6250, bpr = 54785.7227, reg = 3.4243, time = 1.7058]
2025-12-08 23:18:32.237: [iter 51 : loss = 441648.7500, bpr = 54438.3984, reg = 3.6918, time = 1.5923]
2025-12-08 23:18:33.899: [iter 52 : loss = 441388.0625, bpr = 53996.4609, reg = 4.0301, time = 1.6600]
2025-12-08 23:18:35.560: [iter 53 : loss = 440892.6875, bpr = 53541.0898, reg = 4.3841, time = 1.6591]
2025-12-08 23:18:37.149: [iter 54 : loss = 440581.9062, bpr = 53132.1758, reg = 4.7276, time = 1.5879]
2025-12-08 23:18:38.802: [iter 55 : loss = 440136.7188, bpr = 52645.1250, reg = 5.0880, time = 1.6508]
2025-12-08 23:18:40.414: [iter 56 : loss = 439717.0625, bpr = 52133.7500, reg = 5.5200, time = 1.6103]
2025-12-08 23:18:42.080: [iter 57 : loss = 439256.8438, bpr = 51628.1602, reg = 5.9189, time = 1.6642]
2025-12-08 23:18:43.789: [iter 58 : loss = 438601.6250, bpr = 50948.8906, reg = 6.4865, time = 1.7068]
2025-12-08 23:18:45.443: [iter 59 : loss = 438060.2188, bpr = 50362.5156, reg = 6.9999, time = 1.6527]
2025-12-08 23:18:47.139: [iter 60 : loss = 437629.1875, bpr = 49911.8164, reg = 7.4028, time = 1.6944]
2025-12-08 23:18:48.770: [iter 61 : loss = 436900.2500, bpr = 49076.4570, reg = 8.0909, time = 1.6294]
2025-12-08 23:18:50.475: [iter 62 : loss = 436191.7188, bpr = 48366.2188, reg = 8.7264, time = 1.7026]
2025-12-08 23:18:52.115: [iter 63 : loss = 435437.0312, bpr = 47534.8438, reg = 9.4684, time = 1.6385]
2025-12-08 23:18:53.815: [iter 64 : loss = 434724.1250, bpr = 46824.0742, reg = 10.1389, time = 1.6984]
2025-12-08 23:18:55.521: [iter 65 : loss = 433910.9062, bpr = 45938.6523, reg = 10.9644, time = 1.7035]
2025-12-08 23:18:57.171: [iter 66 : loss = 433159.5938, bpr = 45074.8438, reg = 11.8196, time = 1.6485]
2025-12-08 23:18:58.834: [iter 67 : loss = 432220.6562, bpr = 44198.5195, reg = 12.7290, time = 1.6612]
2025-12-08 23:19:00.429: [iter 68 : loss = 431493.5625, bpr = 43359.2188, reg = 13.5824, time = 1.5935]
2025-12-08 23:19:02.128: [iter 69 : loss = 430414.5312, bpr = 42253.4727, reg = 14.7075, time = 1.6967]
2025-12-08 23:19:03.718: [iter 70 : loss = 429478.7188, bpr = 41208.0039, reg = 15.7790, time = 1.5878]
2025-12-08 23:19:05.357: [iter 71 : loss = 428721.6875, bpr = 40242.3516, reg = 16.8852, time = 1.6374]
2025-12-08 23:19:06.996: [iter 72 : loss = 427539.6250, bpr = 39083.7539, reg = 18.2052, time = 1.6366]
2025-12-08 23:19:08.562: [iter 73 : loss = 426501.4375, bpr = 38023.9727, reg = 19.4164, time = 1.5640]
2025-12-08 23:19:10.190: [iter 74 : loss = 425374.6250, bpr = 36913.3047, reg = 20.7972, time = 1.6268]
2025-12-08 23:19:11.751: [iter 75 : loss = 424527.9688, bpr = 35934.7773, reg = 22.1174, time = 1.5598]
2025-12-08 23:19:13.379: [iter 76 : loss = 423468.3750, bpr = 34877.7695, reg = 23.6004, time = 1.6256]
2025-12-08 23:19:14.962: [iter 77 : loss = 422564.8125, bpr = 33836.1250, reg = 24.8877, time = 1.5815]
2025-12-08 23:19:16.612: [iter 78 : loss = 421475.2188, bpr = 32776.6133, reg = 26.4385, time = 1.6479]
2025-12-08 23:19:18.249: [iter 79 : loss = 420363.4375, bpr = 31633.0098, reg = 28.0803, time = 1.6356]
2025-12-08 23:19:19.807: [iter 80 : loss = 419457.1875, bpr = 30566.1641, reg = 29.6896, time = 1.5561]
2025-12-08 23:19:21.452: [iter 81 : loss = 418403.3438, bpr = 29557.8652, reg = 31.3398, time = 1.6432]
2025-12-08 23:19:23.040: [iter 82 : loss = 417561.6875, bpr = 28601.5957, reg = 32.9867, time = 1.5864]
2025-12-08 23:19:24.691: [iter 83 : loss = 416588.3125, bpr = 27651.6816, reg = 34.6536, time = 1.6489]
2025-12-08 23:19:26.338: [iter 84 : loss = 415636.7188, bpr = 26595.8809, reg = 36.4883, time = 1.6453]
2025-12-08 23:19:27.981: [iter 85 : loss = 414615.0938, bpr = 25611.2246, reg = 38.2512, time = 1.6421]
2025-12-08 23:19:29.645: [iter 86 : loss = 413881.4375, bpr = 24724.6367, reg = 40.0230, time = 1.6618]
2025-12-08 23:19:31.241: [iter 87 : loss = 412989.6562, bpr = 23976.5605, reg = 41.7299, time = 1.5938]
2025-12-08 23:19:32.944: [iter 88 : loss = 412251.9062, bpr = 23138.4219, reg = 43.6428, time = 1.7010]
2025-12-08 23:19:34.545: [iter 89 : loss = 411214.4375, bpr = 22169.7676, reg = 45.5160, time = 1.5992]
2025-12-08 23:19:36.189: [iter 90 : loss = 410651.8750, bpr = 21451.7227, reg = 47.3226, time = 1.6422]
2025-12-08 23:19:37.843: [iter 91 : loss = 410052.5312, bpr = 20733.1035, reg = 49.1444, time = 1.6520]
2025-12-08 23:19:39.432: [iter 92 : loss = 409306.0000, bpr = 20025.2500, reg = 50.8793, time = 1.5868]
2025-12-08 23:19:41.090: [iter 93 : loss = 408569.5312, bpr = 19345.8379, reg = 52.8202, time = 1.6561]
2025-12-08 23:19:42.667: [iter 94 : loss = 407981.3750, bpr = 18649.1836, reg = 54.5812, time = 1.5760]
2025-12-08 23:19:44.314: [iter 95 : loss = 407063.0625, bpr = 17817.9844, reg = 56.6571, time = 1.6452]
2025-12-08 23:19:45.974: [iter 96 : loss = 406503.1250, bpr = 17256.4043, reg = 58.4834, time = 1.6582]
2025-12-08 23:19:47.606: [iter 97 : loss = 405940.7188, bpr = 16607.5273, reg = 60.3372, time = 1.6292]
2025-12-08 23:19:49.314: [iter 98 : loss = 405405.8750, bpr = 15994.4824, reg = 62.2772, time = 1.7068]
2025-12-08 23:19:50.968: [iter 99 : loss = 404950.5938, bpr = 15455.3359, reg = 63.8905, time = 1.6523]
2025-12-08 23:19:52.699: [iter 100 : loss = 404164.8438, bpr = 14813.6240, reg = 65.8511, time = 1.7290]
2025-12-08 23:19:52.699: best_result@epoch 0:

2025-12-08 23:19:52.699: training finished without evaluation
2025-12-08 23:19:52.770: export_final_embeddings done: /mnt/sda1/sherry/BiGNAS/SGL-BiGNAS-new/SGL-Torch/dataset/all_data/pretrain-embeddings/SGL/final/
