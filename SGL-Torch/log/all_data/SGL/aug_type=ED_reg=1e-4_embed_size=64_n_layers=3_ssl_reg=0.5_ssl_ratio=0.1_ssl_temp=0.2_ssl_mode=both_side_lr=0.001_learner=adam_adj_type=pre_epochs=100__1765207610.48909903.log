2025-12-08 23:26:50.489: my pid: 368940
2025-12-08 23:26:50.489: model: model.general_recommender.SGL
2025-12-08 23:26:50.489: Dataset statistics:
Name: all_data
The number of users: 2809
The number of items: 45331
The number of ratings: 85936
Average actions of users: 30.59
Average actions of items: 1.90
The sparsity of the dataset: 99.932512%

The number of training: 85936
The number of validation: 0
The number of testing: 0
2025-12-08 23:26:50.489: NeuRec:[NeuRec]:
recommender=SGL
dataset=all_data
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.5
ssl_ratio=0.1
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=100
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=100
pretrain_flag=0
save_flag=0

Command line:
recommender=SGL
dataset=all_data
aug_type=ED
reg=1e-4
n_layers=3
ssl_reg=0.5
ssl_ratio=0.1
ssl_temp=0.2
2025-12-08 23:26:53.368: [iter 1 : loss = 457504.9062, bpr = 59500.9062, reg = 0.2201, time = 1.9738]
2025-12-08 23:26:55.075: [iter 2 : loss = 453233.8438, bpr = 59462.6523, reg = 0.2370, time = 1.7055]
2025-12-08 23:26:56.771: [iter 3 : loss = 451140.6562, bpr = 59426.9961, reg = 0.2520, time = 1.6934]
2025-12-08 23:26:58.425: [iter 4 : loss = 449984.4688, bpr = 59397.8828, reg = 0.2639, time = 1.6528]
2025-12-08 23:27:00.091: [iter 5 : loss = 449024.4062, bpr = 59372.3672, reg = 0.2741, time = 1.6637]
2025-12-08 23:27:01.685: [iter 6 : loss = 448559.5625, bpr = 59352.2539, reg = 0.2840, time = 1.5921]
2025-12-08 23:27:03.399: [iter 7 : loss = 448204.6562, bpr = 59333.0078, reg = 0.2941, time = 1.7107]
2025-12-08 23:27:05.058: [iter 8 : loss = 447799.7188, bpr = 59313.2109, reg = 0.3055, time = 1.6579]
2025-12-08 23:27:06.693: [iter 9 : loss = 447566.0312, bpr = 59294.3906, reg = 0.3180, time = 1.6337]
2025-12-08 23:27:08.402: [iter 10 : loss = 447500.3750, bpr = 59274.1602, reg = 0.3316, time = 1.7068]
2025-12-08 23:27:10.021: [iter 11 : loss = 447335.3750, bpr = 59257.5039, reg = 0.3447, time = 1.6174]
2025-12-08 23:27:11.731: [iter 12 : loss = 447033.4688, bpr = 59237.6016, reg = 0.3599, time = 1.7074]
2025-12-08 23:27:13.318: [iter 13 : loss = 446942.0000, bpr = 59218.9727, reg = 0.3748, time = 1.5854]
2025-12-08 23:27:15.017: [iter 14 : loss = 446810.0000, bpr = 59197.3359, reg = 0.3915, time = 1.6974]
2025-12-08 23:27:16.758: [iter 15 : loss = 446745.0312, bpr = 59177.0625, reg = 0.4081, time = 1.7385]
2025-12-08 23:27:18.445: [iter 16 : loss = 446704.8125, bpr = 59154.8438, reg = 0.4272, time = 1.6857]
2025-12-08 23:27:20.155: [iter 17 : loss = 446586.3438, bpr = 59127.8281, reg = 0.4466, time = 1.7080]
2025-12-08 23:27:21.780: [iter 18 : loss = 446446.0938, bpr = 59098.5312, reg = 0.4654, time = 1.6231]
2025-12-08 23:27:23.431: [iter 19 : loss = 446389.6562, bpr = 59069.6133, reg = 0.4894, time = 1.6502]
2025-12-08 23:27:25.042: [iter 20 : loss = 446253.5000, bpr = 59030.9180, reg = 0.5153, time = 1.6089]
2025-12-08 23:27:26.579: [iter 21 : loss = 446278.2188, bpr = 59001.1602, reg = 0.5371, time = 1.5354]
2025-12-08 23:27:28.186: [iter 22 : loss = 446295.5000, bpr = 58962.4258, reg = 0.5642, time = 1.6059]
2025-12-08 23:27:29.747: [iter 23 : loss = 446111.5000, bpr = 58913.4727, reg = 0.5964, time = 1.5606]
2025-12-08 23:27:31.376: [iter 24 : loss = 446079.6250, bpr = 58877.3164, reg = 0.6230, time = 1.6263]
2025-12-08 23:27:32.997: [iter 25 : loss = 445882.1250, bpr = 58809.4297, reg = 0.6646, time = 1.6205]
2025-12-08 23:27:34.672: [iter 26 : loss = 445887.7812, bpr = 58775.1211, reg = 0.6927, time = 1.6735]
2025-12-08 23:27:36.302: [iter 27 : loss = 445843.4062, bpr = 58708.8516, reg = 0.7328, time = 1.6280]
2025-12-08 23:27:37.840: [iter 28 : loss = 445606.3125, bpr = 58670.4336, reg = 0.7665, time = 1.5368]
2025-12-08 23:27:39.436: [iter 29 : loss = 445555.5625, bpr = 58584.5508, reg = 0.8141, time = 1.5944]
2025-12-08 23:27:40.975: [iter 30 : loss = 445522.2188, bpr = 58503.8477, reg = 0.8658, time = 1.5378]
2025-12-08 23:27:42.574: [iter 31 : loss = 445538.7188, bpr = 58444.2383, reg = 0.9109, time = 1.5979]
2025-12-08 23:27:44.165: [iter 32 : loss = 445328.8125, bpr = 58335.4727, reg = 0.9723, time = 1.5902]
2025-12-08 23:27:45.702: [iter 33 : loss = 445243.4688, bpr = 58276.5234, reg = 1.0170, time = 1.5348]
2025-12-08 23:27:47.299: [iter 34 : loss = 445090.1562, bpr = 58140.3867, reg = 1.1002, time = 1.5962]
2025-12-08 23:27:48.838: [iter 35 : loss = 445076.2188, bpr = 58050.5547, reg = 1.1625, time = 1.5378]
2025-12-08 23:27:50.499: [iter 36 : loss = 444958.0312, bpr = 57928.7070, reg = 1.2432, time = 1.6590]
2025-12-08 23:27:52.108: [iter 37 : loss = 444832.5938, bpr = 57814.2812, reg = 1.3174, time = 1.6067]
2025-12-08 23:27:53.762: [iter 38 : loss = 444598.0000, bpr = 57623.1758, reg = 1.4364, time = 1.6533]
2025-12-08 23:27:55.437: [iter 39 : loss = 444685.6875, bpr = 57502.0078, reg = 1.5202, time = 1.6738]
2025-12-08 23:27:56.989: [iter 40 : loss = 444341.1875, bpr = 57325.2969, reg = 1.6277, time = 1.5504]
2025-12-08 23:27:58.671: [iter 41 : loss = 444241.2500, bpr = 57104.5078, reg = 1.7765, time = 1.6807]
2025-12-08 23:28:00.278: [iter 42 : loss = 444094.3438, bpr = 56951.2617, reg = 1.8937, time = 1.6054]
2025-12-08 23:28:01.937: [iter 43 : loss = 443789.0938, bpr = 56750.9883, reg = 2.0271, time = 1.6577]
2025-12-08 23:28:03.542: [iter 44 : loss = 443669.0000, bpr = 56509.5312, reg = 2.1796, time = 1.6036]
2025-12-08 23:28:05.223: [iter 45 : loss = 443455.0625, bpr = 56263.3789, reg = 2.3596, time = 1.6794]
2025-12-08 23:28:06.902: [iter 46 : loss = 443195.4688, bpr = 56024.6875, reg = 2.5359, time = 1.6777]
2025-12-08 23:28:08.519: [iter 47 : loss = 442954.3750, bpr = 55691.9062, reg = 2.7556, time = 1.6156]
2025-12-08 23:28:10.145: [iter 48 : loss = 442611.4375, bpr = 55404.2344, reg = 2.9788, time = 1.6239]
2025-12-08 23:28:11.746: [iter 49 : loss = 442375.0938, bpr = 55131.2305, reg = 3.1630, time = 1.6000]
2025-12-08 23:28:13.425: [iter 50 : loss = 442071.6250, bpr = 54785.7227, reg = 3.4243, time = 1.6779]
2025-12-08 23:28:15.041: [iter 51 : loss = 441648.7500, bpr = 54438.3984, reg = 3.6918, time = 1.6142]
2025-12-08 23:28:16.722: [iter 52 : loss = 441388.0625, bpr = 53996.4609, reg = 4.0301, time = 1.6797]
2025-12-08 23:28:18.416: [iter 53 : loss = 440892.6875, bpr = 53541.0898, reg = 4.3841, time = 1.6923]
2025-12-08 23:28:20.045: [iter 54 : loss = 440581.9062, bpr = 53132.1758, reg = 4.7276, time = 1.6268]
2025-12-08 23:28:21.717: [iter 55 : loss = 440136.6875, bpr = 52645.1328, reg = 5.0880, time = 1.6705]
2025-12-08 23:28:23.292: [iter 56 : loss = 439717.0938, bpr = 52133.7500, reg = 5.5200, time = 1.5742]
2025-12-08 23:28:24.920: [iter 57 : loss = 439256.8438, bpr = 51628.1602, reg = 5.9189, time = 1.6265]
2025-12-08 23:28:26.553: [iter 58 : loss = 438601.6250, bpr = 50948.8906, reg = 6.4865, time = 1.6312]
2025-12-08 23:28:28.107: [iter 59 : loss = 438060.1562, bpr = 50362.5156, reg = 6.9999, time = 1.5527]
2025-12-08 23:28:29.725: [iter 60 : loss = 437629.1875, bpr = 49911.8164, reg = 7.4028, time = 1.6159]
2025-12-08 23:28:31.273: [iter 61 : loss = 436900.2500, bpr = 49076.4609, reg = 8.0909, time = 1.5469]
2025-12-08 23:28:32.897: [iter 62 : loss = 436191.7188, bpr = 48366.2188, reg = 8.7264, time = 1.6228]
2025-12-08 23:28:34.448: [iter 63 : loss = 435437.0312, bpr = 47534.8438, reg = 9.4684, time = 1.5499]
2025-12-08 23:28:36.060: [iter 64 : loss = 434724.1562, bpr = 46824.0742, reg = 10.1389, time = 1.6101]
2025-12-08 23:28:37.664: [iter 65 : loss = 433910.9062, bpr = 45938.6562, reg = 10.9644, time = 1.6034]
2025-12-08 23:28:39.245: [iter 66 : loss = 433159.5938, bpr = 45074.8438, reg = 11.8196, time = 1.5798]
2025-12-08 23:28:40.867: [iter 67 : loss = 432220.6250, bpr = 44198.5195, reg = 12.7290, time = 1.6205]
2025-12-08 23:28:42.428: [iter 68 : loss = 431493.5625, bpr = 43359.2188, reg = 13.5824, time = 1.5591]
2025-12-08 23:28:44.053: [iter 69 : loss = 430414.5312, bpr = 42253.4727, reg = 14.7075, time = 1.6242]
2025-12-08 23:28:45.611: [iter 70 : loss = 429478.7188, bpr = 41208.0039, reg = 15.7790, time = 1.5570]
2025-12-08 23:28:47.214: [iter 71 : loss = 428721.6875, bpr = 40242.3516, reg = 16.8852, time = 1.6022]
2025-12-08 23:28:48.828: [iter 72 : loss = 427539.6250, bpr = 39083.7539, reg = 18.2052, time = 1.6122]
2025-12-08 23:28:50.384: [iter 73 : loss = 426501.4062, bpr = 38023.9727, reg = 19.4164, time = 1.5548]
2025-12-08 23:28:51.985: [iter 74 : loss = 425374.6250, bpr = 36913.3047, reg = 20.7972, time = 1.5997]
2025-12-08 23:28:53.529: [iter 75 : loss = 424527.9688, bpr = 35934.7773, reg = 22.1174, time = 1.5434]
2025-12-08 23:28:55.175: [iter 76 : loss = 423468.3750, bpr = 34877.7695, reg = 23.6004, time = 1.6447]
2025-12-08 23:28:56.764: [iter 77 : loss = 422564.8125, bpr = 33836.1250, reg = 24.8877, time = 1.5876]
2025-12-08 23:28:58.393: [iter 78 : loss = 421475.2188, bpr = 32776.6172, reg = 26.4385, time = 1.6267]
2025-12-08 23:29:00.036: [iter 79 : loss = 420363.4375, bpr = 31633.0078, reg = 28.0803, time = 1.6422]
2025-12-08 23:29:01.660: [iter 80 : loss = 419457.1875, bpr = 30566.1641, reg = 29.6896, time = 1.6221]
2025-12-08 23:29:03.349: [iter 81 : loss = 418403.3438, bpr = 29557.8633, reg = 31.3398, time = 1.6871]
2025-12-08 23:29:04.968: [iter 82 : loss = 417561.6875, bpr = 28601.5938, reg = 32.9867, time = 1.6176]
2025-12-08 23:29:06.701: [iter 83 : loss = 416588.3125, bpr = 27651.6816, reg = 34.6536, time = 1.7308]
2025-12-08 23:29:08.389: [iter 84 : loss = 415636.7500, bpr = 26595.8770, reg = 36.4883, time = 1.6861]
2025-12-08 23:29:09.947: [iter 85 : loss = 414615.0938, bpr = 25611.2246, reg = 38.2512, time = 1.5568]
2025-12-08 23:29:11.583: [iter 86 : loss = 413881.4688, bpr = 24724.6367, reg = 40.0230, time = 1.6337]
2025-12-08 23:29:13.158: [iter 87 : loss = 412989.6562, bpr = 23976.5586, reg = 41.7299, time = 1.5737]
2025-12-08 23:29:14.797: [iter 88 : loss = 412251.9062, bpr = 23138.4219, reg = 43.6428, time = 1.6370]
2025-12-08 23:29:16.351: [iter 89 : loss = 411214.4375, bpr = 22169.7656, reg = 45.5160, time = 1.5520]
2025-12-08 23:29:17.963: [iter 90 : loss = 410651.8750, bpr = 21451.7227, reg = 47.3226, time = 1.6110]
2025-12-08 23:29:19.584: [iter 91 : loss = 410052.5312, bpr = 20733.1035, reg = 49.1444, time = 1.6198]
2025-12-08 23:29:21.149: [iter 92 : loss = 409306.0000, bpr = 20025.2480, reg = 50.8793, time = 1.5628]
2025-12-08 23:29:22.779: [iter 93 : loss = 408569.5625, bpr = 19345.8379, reg = 52.8202, time = 1.6295]
2025-12-08 23:29:24.382: [iter 94 : loss = 407981.3750, bpr = 18649.1836, reg = 54.5812, time = 1.6006]
2025-12-08 23:29:26.038: [iter 95 : loss = 407063.0625, bpr = 17817.9844, reg = 56.6571, time = 1.6558]
2025-12-08 23:29:27.698: [iter 96 : loss = 406503.1250, bpr = 17256.4023, reg = 58.4834, time = 1.6582]
2025-12-08 23:29:29.288: [iter 97 : loss = 405940.7188, bpr = 16607.5254, reg = 60.3372, time = 1.5890]
2025-12-08 23:29:30.962: [iter 98 : loss = 405405.8750, bpr = 15994.4805, reg = 62.2772, time = 1.6729]
2025-12-08 23:29:32.531: [iter 99 : loss = 404950.5938, bpr = 15455.3350, reg = 63.8905, time = 1.5668]
2025-12-08 23:29:34.200: [iter 100 : loss = 404164.8438, bpr = 14813.6221, reg = 65.8511, time = 1.6681]
2025-12-08 23:29:34.200: best_result@epoch 0:

2025-12-08 23:29:34.200: training finished without evaluation
2025-12-08 23:29:34.269: export_final_embeddings done: /mnt/sda1/sherry/BiGNAS/SGL-BiGNAS-new/SGL-Torch/dataset/all_data/pretrain-embeddings/SGL/final/
