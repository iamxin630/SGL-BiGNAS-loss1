import os
import numpy as np
import torch
import torch.nn.functional as F
import pandas as pd

def find_hard_items_and_export_verbose(
    model,
    groupA_ids,
    hard_user_ids,
    num_users,
    num_source_items,
    num_target_items,
    k_source,
    save_dir,
    preview_top_users
):
    """
        âœ” Source domainï¼šB å–œæ­¡ä½† Hard User ä¸å–œæ­¡ (mean_B - mean_H)
        âŒ Target domainï¼šå…¨éƒ¨ç§»é™¤
    """

    os.makedirs(save_dir, exist_ok=True)
    device = model.device
    model.lightgcn.eval()

    # === Step 1. åŒ¯å‡º embedding ===
    with torch.no_grad():
        uemb, iemb = model.lightgcn._forward_gcn(model.lightgcn.norm_adj)
        uemb = F.normalize(uemb, dim=1)
        iemb = F.normalize(iemb, dim=1)
    print("=" * 80)
    print(f"[1] Embedding ready: user={tuple(uemb.shape)}, item={tuple(iemb.shape)}")

    total_items = iemb.size(0)
    B_users = torch.tensor(groupA_ids, dtype=torch.long, device=device)
    hardU = torch.tensor(hard_user_ids, dtype=torch.long, device=device)

        # === Step 2. è¨ˆç®— Group B / Hard Users çš„é æ¸¬åˆ†æ•¸ ===
    with torch.no_grad():
        # scores_B: [#B, num_items]
        scores_B = model.lightgcn.predict(B_users)
        # mean_B: [num_items]ï¼ˆå°æ‰€æœ‰ Group B å–å¹³å‡ï¼‰
        mean_B = scores_B.mean(dim=0)   # ä¸è¦ keepdimï¼Œå¾Œé¢æ¯”è¼ƒå¥½ç”¨

        # scores_H: [#H, num_items]
        scores_H = model.lightgcn.predict(hardU)

    print("=" * 80)
    print("[2] å·²å–å¾— Group B / Hard Users çš„é æ¸¬åˆ†æ•¸")

    # === Step 2.1 åªå– Source domain çš„ itemï¼ˆç”¨çœŸå¯¦ item id ç¯„åœï¼‰===
    SOURCE_MIN = 2809
    SOURCE_MAX = 31061

    # global item idï¼ˆ= predict å‡ºä¾†çš„ç¬¬å¹¾å€‹æ¬„ä½ indexï¼‰
    source_item_ids = torch.arange(SOURCE_MIN, SOURCE_MAX + 1, device=device)

    # mean_B åœ¨ source domain ä¸Šçš„åˆ†æ•¸: [num_src_items]
    mean_B_src = mean_B[source_item_ids]               # shape: [num_src_items]

    # Hard users åœ¨ source domain ä¸Šçš„åˆ†æ•¸: [#H, num_src_items]
    scores_H_src = scores_H[:, source_item_ids]        # shape: [#H, num_src_items]

    # Debugï¼šç¢ºèªé•·åº¦
    print(">>> DEBUG: num_source_items(from range) =", len(source_item_ids))
    print(">>> DEBUG: source_item_ids[0:5] =", source_item_ids[:5].tolist())
    print(">>> DEBUG: source_item_ids[-5:] =", source_item_ids[-5:].tolist())
    print(">>> DEBUG: mean_B_src shape =", mean_B_src.shape)
    print(">>> DEBUG: scores_H_src shape =", scores_H_src.shape)

    # === Step 2.2 é‡å°ã€Œæ¯å€‹ hard userã€è¨ˆç®— Î”(u, i) = mean_B(i) - score_H(u, i) ===
    # mean_B_src:        [num_src_items]
    # scores_H_src:      [#H, num_src_items]
    # â†’ diff:            [#H, num_src_items]
    diff = mean_B_src.unsqueeze(0) - scores_H_src
    diff = torch.nan_to_num(diff, nan=0.0)

    print("=" * 80)
    print("[2.2] å·²è¨ˆç®—æ¯å€‹ hard user çš„ Î”(u, i) = mean_B(i) - score_H(u, i)")

    # === Step 2.3 å°æ¯å€‹ hard user å€‹åˆ¥åš top-k ===
    num_hard = diff.size(0)
    k_eff = min(k_source, diff.size(1))

    # vals: [#H, k_eff]  æ¯å€‹ hard user çš„ top-k å·®è·å€¼
    # idxs: [#H, k_eff]  å°æ‡‰åœ¨ source_item_ids è£¡çš„ indexï¼ˆ0 ~ num_src_items-1ï¼‰
    vals, idxs = torch.topk(diff, k=k_eff, dim=1)

    # å°æ‡‰å›çœŸæ­£çš„ global item id: [#H, k_eff]
    selected_items_per_user = source_item_ids[idxs]    # shape: [#H, k_eff]

    # Debugï¼šå°å‰å¹¾å€‹ hard user çš„ top-k item
    print("=" * 80)
    print(f"[Source] æ¯å€‹ Hard User å„è‡ª Î” æœ€å¤§çš„ {k_eff} å€‹ source items (å‰ 3 ä½ Hard User)ï¼š")
    for u_row in range(min(3, num_hard)):
        uid = hard_user_ids[u_row]
        items = selected_items_per_user[u_row].cpu().tolist()
        print(f"  Hard User {uid}: items = {items}")

    # === Step 3. åŠ é‚Š ===
    print("\n=== All added source edges ===")
    all_source_edges = []
    preview_log = []

    num_hard = len(hard_user_ids)
    k_eff = selected_items_per_user.size(1)

    for row, uid in enumerate(hard_user_ids):
        for j in range(k_eff):
            iid_global = int(selected_items_per_user[row, j].item())
            all_source_edges.append((uid, iid_global))

            print(f"  + user {uid}  ->  item {iid_global}")

            if len(preview_log) < preview_top_users * k_source:
                local_src_idx = int(idxs[row, j].item())  # åœ¨ source_item_ids è£¡çš„ä½ç½®
                hard_score = float(scores_H_src[row, local_src_idx].item())
                b_mean = float(mean_B_src[local_src_idx].item())
                diff_val = float(vals[row, j].item())
                preview_log.append((uid, iid_global, hard_score, b_mean, diff_val))

    # === Step 4. è¼¸å‡ºç‚º tensor / csv ===
    def make_edge_tensor(edge_list):
        if len(edge_list) == 0:
            return torch.empty((2, 0), dtype=torch.long)
        return torch.tensor(edge_list, dtype=torch.long).t()

    E_add_source = make_edge_tensor(all_source_edges)
    np.save(os.path.join(save_dir, "E_add_source.npy"), E_add_source.cpu().numpy())

    print("=" * 80)
    print(f"[3] å®Œæˆï¼šHard Users = {len(hard_user_ids)}")
    print(f"    Source å‡é‚Šæ•¸é‡ï¼š{E_add_source.size(1)} æ¢")

    # === é è¦½å‰å¹¾ç­† ===
    print("=" * 80)
    print(f"[4] ğŸ” Hard User åŠ é‚Šé è¦½ (å‰ {preview_top_users} ä½)")
    print(f"{'User':>6} | {'Item':>6} | {'HardScore':>10} | {'B_Mean':>10} | {'Î”':>10}")
    print("-" * 60)
    for uid, iid, sc_h, sc_b, diff in preview_log:
        print(f"{uid:>6d} | {iid:>6d} | {sc_h:>10.6f} | {sc_b:>10.6f} | {diff:>10.6f}")

    # === CSV ===
    src_df = pd.DataFrame(E_add_source.cpu().numpy().T, columns=["user_id", "item_id"])
    src_df.to_csv(os.path.join(save_dir, "E_add_source.csv"), index=False)

    print("=" * 80)
    print("[5] è¼¸å‡ºå®Œæˆï¼šsource å‡é‚Š .npy + CSV ç‰ˆ")

    return E_add_source, src_df
